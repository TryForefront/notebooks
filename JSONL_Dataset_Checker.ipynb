{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JSONL Dataset Checker",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### JSONL Dataset Checker\n",
        "Upload your JSONL formatted dataset as \"input.txt\" and execute the following two code blocks to:\n",
        "1. See how many training examples are in your dataset.\n",
        "2. Filter and find prompt-completion pairs that are greater than 2048 tokens. Read more: https://docs.forefront.ai/forefront/master/key-concepts#tokens\n",
        "3. Filter and find prompt-completion pairs that aren't formatted correctly.\n",
        "4. Filter and find completions that don't start with a whitespace character (\" \"). Read more: https://docs.forefront.ai/forefront/guides/fine-tuning#prepare-training-data\n",
        "5. Filter and find prompts that don't end in a common separator. Read more: https://docs.forefront.ai/forefront/guides/fine-tuning#prepare-training-data\n",
        "6. Filter and find completions that don't end with \"<|endoftext|>\".\n",
        "7. Split dataset into training and validation sets to use the validation examples as test prompts.\n"
      ],
      "metadata": {
        "id": "r5lIoDw1xkin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "KM0flMcGqXDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rw-6qncfqNt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ca5e21-9d64-46b0-acdf-6f821bcb2f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Your dataset contains 9293 prompt-completion pairs.\n",
            "\n",
            "###\n",
            "\n",
            "\n",
            "Error: 6 prompt-completion pairs are formatted incorrectly. These are rows: [1, 2, 3, 4, 9292, 9293]\n",
            "\n",
            "\n",
            "There are no prompt-completions pairs that exceed 2048 tokens. Read more: https://docs.forefront.ai/forefront/master/key-concepts#tokens \n",
            "\n",
            "\n",
            "All completions start with a whitespace character. Read more: https://docs.forefront.ai/forefront/guides/fine-tuning#prepare-training-data \n",
            "\n",
            "\n",
            "All prompts end with a common separator. Fixed separator: \"Review:\".\n",
            "\n",
            "\n",
            "All completions end with \"<|endoftext|>\".\n",
            "\n",
            "\n",
            "###\n",
            "\n",
            "\n",
            "6 prompt-completion pairs have been removed due to errors. 9287 prompt-completion pairs are being exported:\n",
            "\n",
            "\n",
            "train.txt: 9282 training examples\n",
            "\n",
            "\n",
            "test_prompts.txt: 5 test examples\n",
            "\n",
            "\n",
            "Download train.txt and test_prompts.txt to start fine-tuning: https://docs.forefront.ai/forefront/guides/fine-tuning#train-a-new-fine-tuned-model \n",
            "\n",
            "\n",
            "If you don't see the files after completion, refresh the page.\n"
          ]
        }
      ],
      "source": [
        "from transformers.utils.dummy_pt_objects import FlaubertWithLMHeadModel\n",
        "import json\n",
        "from transformers import GPT2TokenizerFast\n",
        "from collections import Counter\n",
        "\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
        "i = 0\n",
        "num_dict = {\n",
        "  \"too_long\": 0, \n",
        "  \"bad_examples\": 0, \n",
        "  \"no_whitespace\": 0,\n",
        "  \"no_separator\": 0,\n",
        "  \"no_end\": 0,\n",
        "  # Number of test examples to remove from the training set\n",
        "  \"test_prompts\": 5\n",
        "}\n",
        "arr_dict = {\n",
        "  \"too_long\": [], \n",
        "  \"bad_examples\": [], \n",
        "  \"no_whitespace\": [],\n",
        "  \"no_separator\": [],\n",
        "  \"no_end\": []\n",
        "}\n",
        "separators = []\n",
        "used_separators = {}\n",
        "separator = \"\"\n",
        "\n",
        "\"\"\"\n",
        "Check for fixed separator.\n",
        "\"\"\"\n",
        "with open('input.txt') as fin:\n",
        "  for line in fin:\n",
        "    try:\n",
        "      data = json.loads(line)\n",
        "    except:\n",
        "      continue\n",
        "      \n",
        "    prompt = data['prompt']\n",
        "    separator = prompt.rsplit('\\n', 1)[1]\n",
        "    separators.append(separator)\n",
        "\n",
        "used_separators = (Counter(separators))\n",
        "max_value = max(used_separators.values())\n",
        "\n",
        "if max_value < (i*0.9):\n",
        "  print(f'Error: No fixed separator is used at the end of prompts. Used separators: {used_separators}')\n",
        "\n",
        "max_key = [k for k, v in used_separators.items() if v == max_value]\n",
        "fixed_separator = max_key[0]\n",
        "\n",
        "\"\"\"\n",
        "Filter and find training examples with common errors. Output filtered examples to train.txt and test_prompts.txt.\n",
        "\"\"\"\n",
        "with open('input.txt') as fin:\n",
        "  with open('train.txt', 'w') as ftrain:\n",
        "    with open('test_prompts.txt', 'w') as ftest_prompts:\n",
        "      for line in fin:\n",
        "        i += 1\n",
        "        try:\n",
        "          data = json.loads(line)\n",
        "        except:\n",
        "          num_dict['bad_examples'] += 1\n",
        "          arr_dict['bad_examples'].append(i)\n",
        "          continue\n",
        "          \n",
        "        prompt = data['prompt']\n",
        "        completion = data['completion']\n",
        "        full = f'{prompt}{completion}'\n",
        "\n",
        "        # Filter prompts that don't end with the common separator\n",
        "        separator = prompt.rsplit('\\n', 1)[1]\n",
        "        if separator != fixed_separator:\n",
        "          num_dict['no_separator'] += 1\n",
        "          arr_dict['no_separator'].append(i)\n",
        "          continue\n",
        "\n",
        "        # Filter completions that don't end with <|endoftext|>\n",
        "        if not completion.endswith('<|endoftext|>'):\n",
        "          num_dict['no_end'] += 1\n",
        "          arr_dict['no_end'].append(i)\n",
        "          continue\n",
        "\n",
        "        # Filter completions that don't start with a whitespace\n",
        "        if not completion.startswith(\" \"):\n",
        "          num_dict['no_whitespace'] += 1\n",
        "          arr_dict['no_whitespace'].append(i)\n",
        "          continue\n",
        "\n",
        "        # Filter prompt-completion pairs that are too long (2048 tokens or greater)\n",
        "        length = len(tokenizer.encode(full))\n",
        "        if length > 2047:\n",
        "          num_dict['too_long'] += 1\n",
        "          arr_dict['too_long'].append(i)\n",
        "          continue\n",
        "\n",
        "        # Filter prompt-completion pairs to use for test prompts\n",
        "        if (i <= num_dict['test_prompts']):\n",
        "          ftest_prompts.write(json.dumps({'prompt': prompt, 'completion': completion}))\n",
        "          ftest_prompts.write('\\n')\n",
        "          continue\n",
        "\n",
        "        ftrain.write(json.dumps({'prompt': prompt, 'completion': completion}))\n",
        "        ftrain.write('\\n')\n",
        "\n",
        "\n",
        "filtered_examples = sum(num_dict.values()) - num_dict['test_prompts']\n",
        "export_examples = i - filtered_examples\n",
        "train_examples = export_examples - num_dict['test_prompts']\n",
        "\n",
        "\"\"\"\n",
        "Messages\n",
        "\"\"\"\n",
        "if i > 0:\n",
        "  print(f'\\n\\nYour dataset contains {i} prompt-completion pairs.\\n\\n###\\n\\n')\n",
        "else:\n",
        "  print('Your dataset has no prompt-completion pairs.\\n\\n###\\n\\n')\n",
        "\n",
        "if num_dict['bad_examples'] > 0:\n",
        "  print(f'Error: {num_dict[\"bad_examples\"]} prompt-completion pairs are formatted incorrectly. These are rows: {arr_dict[\"bad_examples\"]}\\n\\n')\n",
        "else:\n",
        "  print('All prompt-completion pairs are formatted properly.\\n\\n')\n",
        "\n",
        "if num_dict['too_long'] > 0:\n",
        "  print(f'Error: {num_dict[\"too_long\"]} prompt-completion pairs exceed 2048 tokens. These are rows: {arr_dict[\"too_long\"]}. Read more: https://docs.forefront.ai/forefront/master/key-concepts#tokens \\n\\n')\n",
        "else:\n",
        "  print('There are no prompt-completions pairs that exceed 2048 tokens. Read more: https://docs.forefront.ai/forefront/master/key-concepts#tokens \\n\\n')\n",
        "\n",
        "if num_dict['no_whitespace'] > 0:\n",
        "  print(f'Error: {num_dict[\"no_whitespace\"]} completions don\\'t start with a whitespace character (\" \"). These are rows: {arr_dict[\"no_whitespace\"]}. Read more: https://docs.forefront.ai/forefront/guides/fine-tuning#prepare-training-data \\n\\n')\n",
        "else:\n",
        "  print('All completions start with a whitespace character. Read more: https://docs.forefront.ai/forefront/guides/fine-tuning#prepare-training-data \\n\\n')\n",
        "\n",
        "if num_dict['no_separator'] > 0:\n",
        "  print(f'Error: {num_dict[\"no_separator\"]} prompt don\\'t end with the common separator. These are rows: {arr_dict[\"no_separator\"]}. Fixed separator: \"{fixed_separator}\". Read more: https://docs.forefront.ai/forefront/guides/fine-tuning#prepare-training-data \\n\\n')\n",
        "else:\n",
        "  print(f'All prompts end with a common separator. Fixed separator: \"{fixed_separator}\".\\n\\n')\n",
        "\n",
        "if num_dict['no_end'] > 0:\n",
        "  print(f'Error: {num_dict[\"no_end\"]} completions don\\'t end with <\\|endoftext\\|>. These are rows: {arr_dict[\"no_end\"]}. Read more: https://docs.forefront.ai/forefront/guides/fine-tuning#prepare-training-data \\n\\n###\\n\\n')\n",
        "else:\n",
        "  print('All completions end with \"<|endoftext|>\".\\n\\n\\n###\\n\\n')\n",
        "\n",
        "if num_dict['bad_examples'] > 0:\n",
        "  print(f'{filtered_examples} prompt-completion pairs have been removed due to errors. {export_examples} prompt-completion pairs are being exported:\\n\\n\\ntrain.txt: {train_examples} training examples\\n\\n\\ntest_prompts.txt: {num_dict[\"test_prompts\"]} test examples\\n\\n\\nDownload train.txt and test_prompts.txt to start fine-tuning: https://docs.forefront.ai/forefront/guides/fine-tuning#train-a-new-fine-tuned-model \\n\\n\\nIf you don\\'t see the files after completion, refresh the page.')\n",
        "else:\n",
        "  print(f'{export_examples} prompt-completion pairs are being exported:\\n\\n\\ntrain.txt: {train_examples} training examples\\n\\n\\ntest_prompts.txt: {num_dict[\"test_prompts\"]} test examples\\n\\n\\nDownload train.txt and test_prompts.txt to start fine-tuning: https://docs.forefront.ai/forefront/guides/fine-tuning#train-a-new-fine-tuned-model \\n\\n\\nIf you don\\'t see the files after completion, refresh the page.')"
      ]
    }
  ]
}