{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resource Benchmarks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmark your Forefront resources\n",
        "The following script can be used to get the response speed and requests per minute profile for a given resource based on your chosen model, resource, and request size (input + output token length)."
      ],
      "metadata": {
        "id": "ci_nkx-GdXuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# Enter the Completions API URL to a model hosted on your resource\n",
        "URL = \"\"\n",
        "# Enter your API key that can be found in Settings -> API Keys\n",
        "API_KEY = \"\"\n",
        "# Enter the average token length of your prompts\n",
        "TOKENS_IN = 300\n",
        "# Enter the average token length of your completions, or max_tokens parameter\n",
        "TOKENS_OUT = 30\n",
        "# Enter the number of trials to average\n",
        "N_TRIALS = 3\n",
        "# Enter the batch size of your resource. Email support@forefront.ai with your model and resource type to get batch size information\n",
        "BATCH_SIZE = 6\n",
        "\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "\n",
        "def make_repetitive_string(n: int) -> str:\n",
        "    out = \"\"\n",
        "    for _ in range(n - 1):\n",
        "        out += \"hello \"\n",
        "    out += \"hello\"\n",
        "    return out\n",
        "\n",
        "\n",
        "def make_request() -> float:\n",
        "\n",
        "    body = {\n",
        "        'prompt': make_repetitive_string(TOKENS_IN),\n",
        "        'max_tokens': TOKENS_OUT,\n",
        "        'repetition_penalty': 0.5,\n",
        "        'temperature': 0.01,\n",
        "        # The n parameter is identical to sending n requests in parallel so it's a simple method to benchmark a single GPU\n",
        "        'n': BATCH_SIZE\n",
        "    }\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    res = requests.post(URL, json=body, headers=headers)\n",
        "\n",
        "    if res.status_code != 200:\n",
        "      print(res.status_code)\n",
        "      raise RuntimeError('Bad status code.')\n",
        "\n",
        "    return time.time() - start\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    total = 0.0\n",
        "\n",
        "    for _ in range(N_TRIALS):\n",
        "      total += make_request()\n",
        "\n",
        "    batch_time = total / N_TRIALS\n",
        "    rpm = 60 / batch_time * BATCH_SIZE\n",
        "\n",
        "    print(f'Requests per minute: {round(rpm)}')\n",
        "    print(f'Response speed: {round(batch_time, 2)} seconds')"
      ],
      "metadata": {
        "id": "D4B7DQXPXsG5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}